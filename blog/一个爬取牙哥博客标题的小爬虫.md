# 一个爬取牙哥博客标题的小爬虫

牙哥给安排了任务让我写一个爬虫爬他博客里面的所有文章的标题。
当时我的思路就是从一个网页开始搜集里面所有的有用的url这个url保存在一个集合中间这样就可以去掉那些重复的url了把已经爬过的url在放到一个集合中间避免重复爬如果出现重复爬的情况的话会让程序没有出口一直循环然后电脑死掉没有其他途径。
好了废话不多说上代码


    #coding=utf-8
    import re
    import requests
    yipafenlei=set()
    weipafenlei=set()#未经爬取分类的url
    yipaweb=set()
    weipaweb=set()#未经爬取的文章url

    def openweb(myurl,zhuangt):

    r=requests.get(myurl)
    # https://www.urlteam.org/2016/11/docker-ubuntu14-04%e4%b8%8a-%e5%ae%89%e8%a3%85-python-pil-image%e7%8e%af%e5%a2%83/
    txt=r.text

    regx  = r'https://www.urlteam.org/category/[\S]*\/' #定义分类的正则表达式规则
    regx1 = r'https://www.urlteam.org/20[\S]*\/&quot;'#定义文章的url正则表达式的规则url后面有一个&quot; 用的时候注意去掉
    regxt = r'&lt;title&gt;[\s\S]*?&lt;/title&gt;'#定义title的正则表达式规则 匹配出 &lt;title&gt;docker ubuntu:14.04上 安装 python-PIL-image环境 | | URl-team&lt;/title&gt;


    pattern = re.compile(regx)
    pattern1 =re.compile(regx1)
    patternt = re.compile(regxt)

    url1=re.findall(pattern,txt)
    for url in url1:
        if url not in yipafenlei:
            weipafenlei.add(url)
            print(url)

    url1=re.findall(pattern1,txt)

    for url in url1:
        url=url[:-2]
        if url not in yipaweb:
            weipaweb.add(url)
            print(url)
    if zhuangt == 1:
        url1=re.findall(patternt,txt)
        f=open('pa.txt','a')
        str1=myurl+url1[0]+'\n\n'
        f.writelines(str1.encode('utf-8'))
        f.close()
    openweb('https://www.urlteam.org',0)
    while True:
    try:

        myurl=weipafenlei.pop()
        yipafenlei.add(myurl)
        openweb(myurl,0)
    except KeyError:
    break
    while True:
    try:

        myurl=weipaweb.pop()
        yipaweb.add(myurl)
        openweb(myurl,1)
    except KeyError:
        break
    print(u"结束")

## 结语

以上是我写的一些东西下面的一些链接就是我参考了哪些人的博客或者文章了
[让 HTTP 服务人类](http://cn.python-requests.org/zh_CN/latest/Requests)

这个是一个requests的官方文档安装什么的都太简单了这里就不多说了

[正则表达式的官方文档（English）](https://docs.python.org/3/library/re.htmlpython3)

[正则表达式的官方文档](https://docs.python.org/2/library/re.htmlpython2)

其实我也看不懂我们可以上网上看看别人翻译好的

[python中的五种异常处理机制介绍](http://www.pythontab.com/html/2014/pythonjichu_0909/866.html)

异常处理很重要呀